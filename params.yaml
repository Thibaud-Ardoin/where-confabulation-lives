# [ System ]
system:
  seed: 1
  verbose: True

# [ Experiment ]
experiment:
  type: "discrimination"
  name: "exp_ActAdd1"
  data: [
    "english_word", 
    "french_word", 
    "celebrity", 
    "airport", 
    "medical", 
    "protein", 
    "culture", 
    "legal",
    # "pokemon",
    # "hallucination_caa",
  ]
  split:
    training_data: [
      # "english_word", 
      # "french_word", 
      "celebrity", 
      # "airport", 
      # "medical", 
      # "protein", 
      # "culture", 
      # "legal"

      # "pokemon"
    ]
    testing_data: [
      "english_word", 
      "french_word",
      # "celebrity", 
      "airport", 
      "medical", 
      "protein", 
      "culture", 
      "legal"
    ]

# [ Data ]
prepare:
  seed: 0
  text_data_folder: "data/text"
  prepared_data_folder: "data/prepared"
  output_file_name: "inference"
  prompt_file: "prompts.yaml"

# [ Inference ]
inference:
  seed: 1
  model_name: "Qwen2.5-14B-Instruct" #"Gemma-2b" #"Meta-Llama-3-8B-Instruct" #"Gemma-2b" #Meta-Llama-3-8B-Instruct" # "Meta-Llama-3-8B-Instruct" #"gpt2-small" #"Meta-Llama-3-8B-Instruct"
  model_path: "models/Meta-Llama-3-8B-Instruct/"
  tokenizer_path: "models/Meta-Llama-3-8B-Instruct/tokenizer.model"
  torch_dtype: "torch.bfloat16"
  temperature: 0.6
  top_p: 0.9
  max_seq_len: 512 #512
  max_batch_size: 8
  generation_verbose: True

  inference_data_folder: "data/inference"
  prompt_token: True
  token_places: "first_gen" #"all" #"first_gen" #[0] #"all" #[-1]
  layers: "all" 
  save_input_token: True


# [ Projection ]
projection:
  seed: 0
  projection_data_folder: "data/projected"
  projection_model_path: "models/projection/"
  zero_centered: True # Substract the mean of each data name
  slerp_interpolation: False
  first_gen: True             # ? Should be changed if we harvest alreaddy only the first token in inference
  proj_layer: 0
  projections:
    # PCAProjectionModel:
    #   n_components: 2
    SparsePCAProjectionModel:
      n_components: 2
      alpha: 0.2
    # LDAProjectionModel:
    #   n_components: 2
    # NoProjectionModel:
    #   n_components: 4096
  # steeve_type: "proj+mean+inv"
  # steering_vector:
  #   ["proj+mean+inv"]
    #, "mean"]


# [ Detection ]
detection:
  seed: 1
  detection_data_folder: "data/detection"
  detection_model_path: "models/detection/"
  detection_models:
    # SimilarityDetectionModel:
    #   threshold: 0
    # SVCDetectionModel:
    #   max_iter: 1000
    #   probability: True
    SGDDetectionModel:
      max_iter: 5
      loss: "log_loss"
    # XGBDetectionModel:
    #   n_estimators: 10
    #   max_depth: 3
    #   learning_rate: 0.1
    #   subsample: 0.5
    #   colsample_bytree: 0.5
    #   gamma: 0
    #   reg_alpha: 0
    #   reg_lambda: 1
    #   objective: "binary:logistic"
    #   eval_metric: "logloss"
    #   verbosity: 0

# [ Manipulation ]
manipulation: 
  switch: False
  additive_vector_path: "LLMs/mri_llm/inference_data/proj.pkl" 
  PCA_projection_path: "LLMs/mri_llm/inference_data/unit_delta.pkl" 
  layer: 14



# [ Evaluation ]
evaluation:
  evaluation_folder: "eval/"
  seed: 1
  


# [ Visualization ]
palette: [
  "#ee6a00",
  "#eeff41",
  "#009667",
  "#cd92d7",
  "#b3a77d",
  "#a1e8d9"
]

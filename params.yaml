# [ System ]
system:
  seed: 1
  verbose: True

experiment:
  name: "exp2"
  data: ["celebrity", "english_word"]
  split:
    training_data: ["english_word"]
    testing_data: ["celebrity"]

# [ Data ]
prepare:
  seed: 1
  text_data_folder: "data/text"
  prepared_data_folder: "data/prepared"
  # [ Prompts ]
  inputs:
    conspiracy:
      switches:         ["real", "fake"]
      system_prompts:   ["Always respond with a SINGLE sentence. You are given the name of an historical phenomena, give me a short neutral description."]
      user_prompts:     ['{}:']
      sufix: "horizontal+token"

    test_celebrity:
      switches:         ["real", "fake"]
      system_prompts:   [
        "Always respond with a SINGLE sentence.",
      ]
      user_prompts:     ['Do you know {}?']
      sufix: "test"

    celebrity:
      switches:         ["real", "fake"]
      system_prompts:   [
        # "Always respond with a SINGLE year date. You are given the name of a personality, give me an unrelated fully random date based on that."
        # "Always respond with a SINGLE date. You are given the name of a personality, give me it's date of birth. \n Nicolaus Copernicus: 1473 \n Ed Sheeran: 1991 \n Angela Merkel: 1954 \n Victor Hugo: 1802",
        "Always respond with a SINGLE sentence. You are given the name of a personality, give me a short description.",
      ]
      user_prompts:     ['{}:']
    #   # sufix: "random"
      sufix: "horizontal+token"

    english_word:
      switches:         ["real", "fake"]
      system_prompts:   [
        # "Always respond with a SINGLE word. You are given an english word, give me a Synonym. \n Cloud: Nebula \n Bridge: Span \n Cup: Mug \n Service: Assistance",
        "Always respond with a SINGLE sentence. You are given an english word, give me a short definition.",
      ]
      user_prompts:     ['{}:']
      sufix: "horizontal+token"

    french_word:
      switches:         ["real", "fake"]
      system_prompts:   [
        # "Always respond with a SINGLE word. You are given an english word, give me a Synonym. \n Cloud: Nebula \n Bridge: Span \n Cup: Mug \n Service: Assistance",
        "Repond toujours avec UN SEUL mot. A partir d'un mot français, donne moi un synonyme. \n Nuage: Cumulus \n Pont: Arche \n Tasse: Gobelet \n Outillage: Meteriel",
        # "Repond toujours en une SEULE phrase. A partir d'un mot français, donne moi une courte definition.",
      ]
      user_prompts:     ['{}:']
      sufix: "horizontal+token"

    date:
      switches:         ["real", "fake"]
      system_prompts:   [
        "Always respond only YES or NO.",
      ]
      user_prompts:     ['Does {} end with a 1?']

    election:
      switches:         ["2024", "2022", "2010"]
      system_prompts:   [
        "Always respond only YES or NO.",
      ]
      user_prompts:     ['Could you list events that happend during the presidential election of {}?']
      sufix: "yes-no"

    character:
      switches:         ["real", "fake"]
      system_prompts:   ["Always respond with a SINGLE sentence. You are given a character name, give me a short description."]
      user_prompts:     ['{}:']
      sufix: "horizontal"

  output_file_name: "inference"



# [ Inference ]
inference:
  seed: 1
  model_path: "models/Meta-Llama-3-8B-Instruct/"
  tokenizer_path: "models/Meta-Llama-3-8B-Instruct/tokenizer.model"
  temperature: 0.5
  top_p: 0.9
  max_seq_len: 512
  max_batch_size: 8
  generation_verbose: False

  inference_data_folder: "data/inference"
  prompt_token: True
  token_places: "all" #[-1]
  layers: [16] #"all"
  save_input_token: True


# [ Projection ]
projection:
  seed: 1
  projection_data_folder: "data/projected"
  projection_model_path: "models/projection/"
  projections:
    PCAProjectionModel:
      n_components: 4
    # SparsePCAProjectionModel:
    #   n_components: 2
    #   alpha: 0.7
    # LDAProjectionModel:
    #   n_components: 2

  steering_vector:
    ["proj+mean+inv"]
    #, "mean"]


# [ Detection ]
detection:
  seed: 1
  detection_data_folder: "data/detection"
  detection_model_path: "models/detection/"
  detection_models:
    SVCDetectionModel:
      max_iter: 100
      probability: True
    # SGDDetectionModel:
    #   max_iter: 5
    #   loss: "log_loss"
    # XGBDetectionModel:
    #   n_estimators: 100
    #   max_depth: 3
    #   learning_rate: 0.1
    #   subsample: 0.5
    #   colsample_bytree: 0.5
    #   gamma: 0
    #   reg_alpha: 0
    #   reg_lambda: 1
    #   objective: "binary:logistic"
    #   eval_metric: "logloss"
    #   verbosity: 0

# [ Manipulation ]
manipulation: 
  switch: False
  additive_vector_path: "LLMs/mri_llm/inference_data/proj.pkl" 
  PCA_projection_path: "LLMs/mri_llm/inference_data/unit_delta.pkl" 
  layer: 16



# [ Evaluation ]
evaluation:
  evaluation_folder: "eval/"
  seed: 1

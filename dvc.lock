schema: '2.0'
stages:
  prepare:
    cmd: python src/prepare.py
    deps:
    - path: data/text/
      hash: md5
      md5: 9cc7759e0177b243978c44053556818a.dir
      size: 41021
      nfiles: 23
    - path: src/prepare.py
      hash: md5
      md5: 695e36a6210d0912d618308df1abb8d7
      size: 983
    params:
      params.yaml:
        experiment.data:
        - celebrity
        - english_word
        prepare:
          seed: 1
          text_data_folder: data/text
          prepared_data_folder: data/prepared
          inputs:
            conspiracy:
              switches:
              - real
              - fake
              system_prompts:
              - Always respond with a SINGLE sentence. You are given the name of an
                historical phenomena, give me a short neutral description.
              user_prompts:
              - '{}:'
              sufix: horizontal+token
            celebrity:
              switches:
              - real
              - fake
              system_prompts:
              - "Always respond with a SINGLE date. You are given the name of a personality,
                give me it's date of birth. \n Nicolaus Copernicus: 1473 \n Ed Sheeran:
                1991 \n Angela Merkel: 1954 \n Victor Hugo: 1802"
              user_prompts:
              - '{}:'
              sufix: horizontal+token
            english_word:
              switches:
              - real
              - fake
              system_prompts:
              - "Always respond with a SINGLE word. You are given an english word,
                give me a Synonym. \n Cloud: Nebula \n Bridge: Span \n Cup: Mug \n
                Service: Assistance"
              user_prompts:
              - '{}:'
              sufix: horizontal+token
            french_word:
              switches:
              - real
              - fake
              system_prompts:
              - "Repond toujours avec UN SEUL mot. A partir d'un mot fran√ßais, donne
                moi un synonyme. \n Nuage: Cumulus \n Pont: Arche \n Tasse: Gobelet
                \n Outillage: Meteriel"
              user_prompts:
              - '{}:'
              sufix: horizontal+token
            date:
              switches:
              - real
              - fake
              system_prompts:
              - Always respond only YES or NO.
              user_prompts:
              - Does {} end with a 1?
            election:
              switches:
              - '2024'
              - '2022'
              - '2010'
              system_prompts:
              - Always respond only YES or NO.
              user_prompts:
              - Could you list events that happend during the presidential election
                of {}?
              sufix: yes-no
            character:
              switches:
              - real
              - fake
              system_prompts:
              - Always respond with a SINGLE sentence. You are given a character name,
                give me a short description.
              user_prompts:
              - '{}:'
              sufix: horizontal
          output_file_name: inference
    outs:
    - path: data/prepared
      hash: md5
      md5: f4f46142e43561222acfdf1faf8e1ed0.dir
      size: 22878
      nfiles: 2
  inference:
    cmd: torchrun src/inference.py
    deps:
    - path: data/prepared/
      hash: md5
      md5: f4f46142e43561222acfdf1faf8e1ed0.dir
      size: 22878
      nfiles: 2
    - path: src/inference.py
      hash: md5
      md5: 9588f3657c3f6b248af59a26c044a9e1
      size: 7672
    params:
      params.yaml:
        experiment.data:
        - celebrity
        - english_word
        inference:
          seed: 1
          model_path: models/Meta-Llama-3-8B-Instruct/
          tokenizer_path: models/Meta-Llama-3-8B-Instruct/tokenizer.model
          temperature: 0.5
          top_p: 0.9
          max_seq_len: 512
          max_batch_size: 8
          generation_verbose: false
          inference_data_folder: data/inference
          prompt_token: true
          token_places: all
          layers:
          - 16
          save_input_token: true
    outs:
    - path: data/inference
      hash: md5
      md5: 953ca16e737da79efc32da3d75dd10b3.dir
      size: 12180806370
      nfiles: 2
  detection:
    cmd: python src/detection.py
    deps:
    - path: data/projected/
      hash: md5
      md5: 7f814a3966ba844b97ef48b0e5f745bb.dir
      size: 185891096
      nfiles: 3
    - path: src/detection.py
      hash: md5
      md5: 7a2ea3d77275eae6a433295be0607f3d
      size: 4484
    params:
      params.yaml:
        detection:
          seed: 1
          detection_data_folder: data/detection
          detection_model_path: models/detection/
          detection_models:
            SVCDetectionModel:
              max_iter: 100
              probability: true
            SGDDetectionModel:
              max_iter: 5
              loss: log_loss
            XGBDetectionModel:
              n_estimators: 100
              max_depth: 3
              learning_rate: 0.1
              subsample: 0.5
              colsample_bytree: 0.5
              gamma: 0
              reg_alpha: 0
              reg_lambda: 1
              objective: binary:logistic
              eval_metric: logloss
              verbosity: 0
        experiment.split:
          training_data:
          - english_word
          testing_data:
          - celebrity
    outs:
    - path: data/detection
      hash: md5
      md5: 89c8d5f25aadccc98605ed4e1993ff6f.dir
      size: 185897755
      nfiles: 2
    - path: models/detection
      hash: md5
      md5: 4f7e62cd47a39012fdc378ac4cb0d351.dir
      size: 90725
      nfiles: 3
  projection:
    cmd: python src/projection.py
    deps:
    - path: data/inference/
      hash: md5
      md5: 953ca16e737da79efc32da3d75dd10b3.dir
      size: 12180806370
      nfiles: 2
    - path: src/projection.py
      hash: md5
      md5: e991381a58b8ea2996b56ac73f113479
      size: 7313
    params:
      params.yaml:
        experiment.split:
          training_data:
          - english_word
          testing_data:
          - celebrity
        projection:
          seed: 1
          projection_data_folder: data/projected
          projection_model_path: models/projection/
          projections:
            PCAProjectionModel:
              n_components: 2
            SparsePCAProjectionModel:
              n_components: 2
          steering_vector:
          - proj+mean+inv
          - mean
    outs:
    - path: data/projected
      hash: md5
      md5: 7f814a3966ba844b97ef48b0e5f745bb.dir
      size: 185891096
      nfiles: 3
    - path: models/projection
      hash: md5
      md5: e42a7ff658b46e5d5e613b982445bce2.dir
      size: 134318156
      nfiles: 2
  evaluation:
    cmd: python src/evaluation.py
    deps:
    - path: data/projected/
      hash: md5
      md5: 7f814a3966ba844b97ef48b0e5f745bb.dir
      size: 185891096
      nfiles: 3
    - path: models/detection
      hash: md5
      md5: 4f7e62cd47a39012fdc378ac4cb0d351.dir
      size: 90725
      nfiles: 3
    - path: src/evaluation.py
      hash: md5
      md5: f883a3c47fd3418ecd5f86741ee7cd1a
      size: 6381
    params:
      params.yaml:
        evaluation:
          evaluation_folder: eval/
          seed: 1
        experiment.split:
          training_data:
          - english_word
          testing_data:
          - celebrity
    outs:
    - path: eval
      hash: md5
      md5: 31e9a0435d40a400ee75eec77823445c.dir
      size: 52304
      nfiles: 21

schema: '2.0'
stages:
  prepare:
    cmd: python src/prepare.py
    deps:
    - path: data/text/
      hash: md5
      md5: 400b0b45c658661ed3c405debd1417d2.dir
      size: 41386
      nfiles: 25
    - path: src/prepare.py
      hash: md5
      md5: 695e36a6210d0912d618308df1abb8d7
      size: 983
    params:
      params.yaml:
        experiment.data:
        - celebrity
        - english_word
        prepare:
          seed: 1
          text_data_folder: data/text
          prepared_data_folder: data/prepared
          inputs:
            conspiracy:
              switches:
              - real
              - fake
              system_prompts:
              - Always respond with a SINGLE sentence. You are given the name of an
                historical phenomena, give me a short neutral description.
              user_prompts:
              - '{}:'
              sufix: horizontal+token
            test_celebrity:
              switches:
              - real
              - fake
              system_prompts:
              - Always respond with a SINGLE sentence. You are given the name of a
                personality, give me a short description.
              user_prompts:
              - '{}:'
              sufix: test
            celebrity:
              switches:
              - real
              - fake
              system_prompts:
              - Always respond with a SINGLE sentence. You are given the name of a
                personality, give me a short description.
              user_prompts:
              - '{}:'
              sufix: horizontal+token
            english_word:
              switches:
              - real
              - fake
              system_prompts:
              - Always respond with a SINGLE sentence. You are given an english word,
                give me a short definition.
              user_prompts:
              - '{}:'
              sufix: horizontal+token
            french_word:
              switches:
              - real
              - fake
              system_prompts:
              - "Repond toujours avec UN SEUL mot. A partir d'un mot fran√ßais, donne
                moi un synonyme. \n Nuage: Cumulus \n Pont: Arche \n Tasse: Gobelet
                \n Outillage: Meteriel"
              user_prompts:
              - '{}:'
              sufix: horizontal+token
            date:
              switches:
              - real
              - fake
              system_prompts:
              - Always respond only YES or NO.
              user_prompts:
              - Does {} end with a 1?
            election:
              switches:
              - '2024'
              - '2022'
              - '2010'
              system_prompts:
              - Always respond only YES or NO.
              user_prompts:
              - Could you list events that happend during the presidential election
                of {}?
              sufix: yes-no
            character:
              switches:
              - real
              - fake
              system_prompts:
              - Always respond with a SINGLE sentence. You are given a character name,
                give me a short description.
              user_prompts:
              - '{}:'
              sufix: horizontal
          output_file_name: inference
    outs:
    - path: data/prepared
      hash: md5
      md5: c56410cf004a1b58170586c3f016a6a8.dir
      size: 22743
      nfiles: 2
  inference:
    cmd: torchrun src/inference.py
    deps:
    - path: data/prepared/
      hash: md5
      md5: c56410cf004a1b58170586c3f016a6a8.dir
      size: 22743
      nfiles: 2
    - path: src/inference.py
      hash: md5
      md5: 9588f3657c3f6b248af59a26c044a9e1
      size: 7672
    params:
      params.yaml:
        experiment.data:
        - celebrity
        - english_word
        inference:
          seed: 1
          model_path: models/Meta-Llama-3-8B-Instruct/
          tokenizer_path: models/Meta-Llama-3-8B-Instruct/tokenizer.model
          temperature: 0.5
          top_p: 0.9
          max_seq_len: 512
          max_batch_size: 8
          generation_verbose: false
          inference_data_folder: data/inference
          prompt_token: true
          token_places: all
          layers:
          - 16
          save_input_token: true
    outs:
    - path: data/inference
      hash: md5
      md5: 1ba1083ba69939c3c9fbcb6de1b61484.dir
      size: 4668527056
      nfiles: 2
  detection:
    cmd: python src/detection.py
    deps:
    - path: data/projected/
      hash: md5
      md5: d9ca0a577665b5dc9b893b0336a97237.dir
      size: 188606249
      nfiles: 3
    - path: src/detection.py
      hash: md5
      md5: 7a2ea3d77275eae6a433295be0607f3d
      size: 4484
    params:
      params.yaml:
        detection:
          seed: 1
          detection_data_folder: data/detection
          detection_model_path: models/detection/
          detection_models:
            SVCDetectionModel:
              max_iter: 100
              probability: true
        experiment.split:
          training_data:
          - english_word
          testing_data:
          - celebrity
    outs:
    - path: data/detection
      hash: md5
      md5: 24dc2c248160260714cb6cbb20960f6c.dir
      size: 188547236
      nfiles: 2
    - path: models/detection
      hash: md5
      md5: 7a38f60033fd95eb17bf6a19690e586d.dir
      size: 2587
      nfiles: 1
  projection:
    cmd: python src/projection.py
    deps:
    - path: data/inference/
      hash: md5
      md5: 1ba1083ba69939c3c9fbcb6de1b61484.dir
      size: 4668527056
      nfiles: 2
    - path: src/projection.py
      hash: md5
      md5: ec3166f9610cb3623e28d26295822c30
      size: 7912
    params:
      params.yaml:
        experiment.split:
          training_data:
          - english_word
          testing_data:
          - celebrity
        projection:
          seed: 1
          projection_data_folder: data/projected
          projection_model_path: models/projection/
          projections:
            PCAProjectionModel:
              n_components: 4
          steering_vector:
          - proj+mean+inv
    outs:
    - path: data/projected
      hash: md5
      md5: d9ca0a577665b5dc9b893b0336a97237.dir
      size: 188606249
      nfiles: 3
    - path: models/projection
      hash: md5
      md5: f106e3264c5fb24ff2a1635b2268281e.dir
      size: 134382725
      nfiles: 1
  evaluation:
    cmd: python src/evaluation.py
    deps:
    - path: data/projected/
      hash: md5
      md5: d9ca0a577665b5dc9b893b0336a97237.dir
      size: 188606249
      nfiles: 3
    - path: models/detection
      hash: md5
      md5: 7a38f60033fd95eb17bf6a19690e586d.dir
      size: 2587
      nfiles: 1
    - path: src/evaluation.py
      hash: md5
      md5: 17093d22a15753510ffaf989db64b332
      size: 6731
    params:
      params.yaml:
        evaluation:
          evaluation_folder: eval/
          seed: 1
        experiment.split:
          training_data:
          - english_word
          testing_data:
          - celebrity
    outs:
    - path: eval
      hash: md5
      md5: 17db73ba0794ff6a01587f2ad415a238.dir
      size: 3705264
      nfiles: 10

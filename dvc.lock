schema: '2.0'
stages:
  prepare:
    cmd: python src/prepare.py
    deps:
    - path: data/text/
      hash: md5
      md5: 9cc7759e0177b243978c44053556818a.dir
      size: 41021
      nfiles: 23
    - path: src/prepare.py
      hash: md5
      md5: 90617edb2a9ca16c46094d075bc1b982
      size: 1028
    params:
      params.yaml:
        experiment:
          name: exp1
          training_data:
          - english_word
          testing_data:
          - celebrity
        prepare:
          seed: 1
          text_data_folder: data/text
          prepared_data_folder: data/prepared
          inputs:
            conspiracy:
              switches:
              - real
              - fake
              system_prompts:
              - Always respond with a SINGLE sentence. You are given the name of an
                historical phenomena, give me a short neutral description.
              user_prompts:
              - '{}:'
              sufix: horizontal+token
            celebrity:
              switches:
              - real
              - fake
              system_prompts:
              - "Always respond with a SINGLE date. You are given the name of a personality,
                give me it's date of birth. \n Nicolaus Copernicus: 1473 \n Ed Sheeran:
                1991 \n Angela Merkel: 1954 \n Victor Hugo: 1802"
              user_prompts:
              - '{}:'
              sufix: horizontal+token
            english_word:
              switches:
              - real
              - fake
              system_prompts:
              - "Always respond with a SINGLE word. You are given an english word,
                give me a Synonym. \n Cloud: Nebula \n Bridge: Span \n Cup: Mug \n
                Service: Assistance"
              user_prompts:
              - '{}:'
              sufix: horizontal+token
            french_word:
              switches:
              - real
              - fake
              system_prompts:
              - "Repond toujours avec UN SEUL mot. A partir d'un mot fran√ßais, donne
                moi un synonyme. \n Nuage: Cumulus \n Pont: Arche \n Tasse: Gobelet
                \n Outillage: Meteriel"
              user_prompts:
              - '{}:'
              sufix: horizontal+token
            date:
              switches:
              - real
              - fake
              system_prompts:
              - Always respond only YES or NO.
              user_prompts:
              - Does {} end with a 1?
            election:
              switches:
              - '2024'
              - '2022'
              - '2010'
              system_prompts:
              - Always respond only YES or NO.
              user_prompts:
              - Could you list events that happend during the presidential election
                of {}?
              sufix: yes-no
            character:
              switches:
              - real
              - fake
              system_prompts:
              - Always respond with a SINGLE sentence. You are given a character name,
                give me a short description.
              user_prompts:
              - '{}:'
              sufix: horizontal
          output_file_name: inference
    outs:
    - path: data/prepared
      hash: md5
      md5: 5406f01800694a27a75df1ade358b661.dir
      size: 22878
      nfiles: 2
  inference:
    cmd: torchrun src/inference.py
    deps:
    - path: data/prepared/
      hash: md5
      md5: 5406f01800694a27a75df1ade358b661.dir
      size: 22878
      nfiles: 2
    - path: src/inference.py
      hash: md5
      md5: 99b37ae7a807916cfffc4f5eff074bec
      size: 7717
    params:
      params.yaml:
        experiment:
          name: exp1
          training_data:
          - english_word
          testing_data:
          - celebrity
        inference:
          seed: 1
          model_path: models/Meta-Llama-3-8B-Instruct/
          tokenizer_path: models/Meta-Llama-3-8B-Instruct/tokenizer.model
          temperature: 0.5
          top_p: 0.9
          max_seq_len: 512
          max_batch_size: 8
          generation_verbose: false
          inference_data_folder: data/inference
          prompt_token: true
          token_places: all
          layers:
          - 16
          save_input_token: true
    outs:
    - path: data/inference
      hash: md5
      md5: 3402b7b3c8a3fc936ebe1f7870986ee1.dir
      size: 12181069366
      nfiles: 6
  detection:
    cmd: python src/detection.py
    deps:
    - path: data/projected/
      hash: md5
      md5: 5b7421fc5fe806cf6207fe0da5c900dd.dir
      size: 185863168
      nfiles: 2
    - path: src/detection.py
      hash: md5
      md5: c034dbd1481264a5c9f5c8d095d6e034
      size: 4448
    params:
      params.yaml:
        detection:
          seed: 1
          detection_data_folder: data/detection
          detection_model_path: models/detection/
          detection_models:
            SVCDetectionModel:
              max_iter: 100
              probability: true
            SGDDetectionModel:
              max_iter: 5
              loss: log_loss
            XGBDetectionModel:
              n_estimators: 100
              max_depth: 3
              learning_rate: 0.1
              subsample: 0.5
              colsample_bytree: 0.5
              gamma: 0
              reg_alpha: 0
              reg_lambda: 1
              objective: binary:logistic
              eval_metric: logloss
              verbosity: 0
    outs:
    - path: data/detection
      hash: md5
      md5: 0640964c2557b3ac25e06b77fa0c3f13.dir
      size: 185870439
      nfiles: 2
    - path: models/detection
      hash: md5
      md5: d35739c3c9ece9ac05e0dce6f5bcb0be.dir
      size: 91522
      nfiles: 3
  projection:
    cmd: python src/projection.py
    deps:
    - path: data/inference/
      hash: md5
      md5: 3402b7b3c8a3fc936ebe1f7870986ee1.dir
      size: 12181069366
      nfiles: 6
    - path: src/projection.py
      hash: md5
      md5: a5f7f31aa9a4a82d1861b731ec7c6abf
      size: 4624
    params:
      params.yaml:
        projection:
          seed: 1
          projection_data_folder: data/projected
          projection_model_path: models/projection/
          projections:
            PCAProjectionModel:
              n_components: 4
    outs:
    - path: data/projected
      hash: md5
      md5: 5b7421fc5fe806cf6207fe0da5c900dd.dir
      size: 185863168
      nfiles: 2
    - path: models/projection
      hash: md5
      md5: 2fbc20b2297d5d2d6559e42d94a4acc0.dir
      size: 134382688
      nfiles: 1
  evaluation:
    cmd: python src/evaluation.py
    deps:
    - path: data/projected/
      hash: md5
      md5: 5b7421fc5fe806cf6207fe0da5c900dd.dir
      size: 185863168
      nfiles: 2
    - path: models/detection
      hash: md5
      md5: d35739c3c9ece9ac05e0dce6f5bcb0be.dir
      size: 91522
      nfiles: 3
    - path: src/evaluation.py
      hash: md5
      md5: e3891584086f6ba9b8d49b4b382277a8
      size: 5489
    params:
      params.yaml:
        evaluation:
          evaluation_folder: eval/
          seed: 1
    outs:
    - path: eval
      hash: md5
      md5: 2741984af023b4f47a386c329b70ddec.dir
      size: 52716
      nfiles: 21
